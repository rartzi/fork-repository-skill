#!/usr/bin/env python3
"""
Codex/OpenAI CLI Wrapper for E2B Sandboxes

Provides a CLI interface for OpenAI using the OpenAI API.
This allows running Codex/GPT in E2B sandboxes where the full CLI isn't available.
"""

import sys
import os
from openai import OpenAI

def main():
    # Check for API key
    api_key = os.environ.get('OPENAI_API_KEY')
    if not api_key:
        print("Error: OPENAI_API_KEY environment variable not set", file=sys.stderr)
        sys.exit(1)

    # Parse arguments
    prompt_mode = '-p' in sys.argv or '--prompt' in sys.argv
    model_name = None

    # Extract prompt
    args = sys.argv[1:]

    # Remove flags
    args = [arg for arg in args if arg not in ['-p', '--prompt']]

    # Check for model override
    if '--model' in sys.argv:
        model_idx = sys.argv.index('--model')
        if model_idx + 1 < len(sys.argv):
            model_name = sys.argv[model_idx + 1]
            args = [arg for arg in args if arg not in ['--model', model_name]]

    # Get prompt
    if args:
        prompt = ' '.join(args)
    elif not sys.stdin.isatty():
        # Read from stdin if piped
        prompt = sys.stdin.read().strip()
    else:
        prompt = None

    if not prompt:
        print("Usage: codex [-p] [--model MODEL] <prompt>", file=sys.stderr)
        print("   or: echo 'prompt' | codex", file=sys.stderr)
        sys.exit(1)

    # Use OpenAI API
    try:
        client = OpenAI(api_key=api_key)

        # Default to GPT-4
        model = model_name or "gpt-4-turbo-preview"

        response = client.chat.completions.create(
            model=model,
            messages=[{
                "role": "user",
                "content": prompt
            }]
        )

        # Output response
        print(response.choices[0].message.content)

    except Exception as e:
        print(f"Error: {e}", file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    main()
